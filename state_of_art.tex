\section{The State-of-Art Approach}
Before presenting our solution {\methodName} for uncertain graph sharing, we first describe the state-of-art approach~\cite{Boldi_Injecting_2012}. The main purpose of describing it is to separate the basic framework with the key idea of {\methodName}. 

\subsection{Overview}~~In general, it obfuscates graph data $G=(V,E)$ by adding or removing edges \emph{partially}. For each edge $e$, it assigns a probability deviation $r_{e}$, where $r_{e} \leftarrow R(\sigma)$. In specific, the uncertainty injecting scheme proceeds as follows:
\begin{equation}
	p(e) =
	\begin{cases}
		 1-r_{e}  & e \in E \\
		 r_{e}    & otherwise 
	\end{cases}
	\label{eq:inject}
\end{equation}

Boldi {\etal}~\cite{Boldi_Injecting_2012} suggest the use of the truncated normal distribution with mean 0 and variance $\sigma^2$ for generating distribution of $r_{e}$. While, $R$ could in principle be any distribution. As the standard deviation $\sigma$ decreases, a greater mass of $R_{\sigma}$ will concentrate near $r_{e}=0$.  Then, the amount of injected noise and consequent structural distortion  will be smaller. Aiming at high utility, it aims at injecting the minimal amount of uncertainty need to achieve the required obfuscation. 
Computing the minimal amount of uncertainty is achieved via a binary search on the value of standard deviation $\sigma$, as outlined in Algorithm~\ref{alg:obf}. 
\input{mainRoutine.tex}

The search flow is determined by the function {\genobf}. The function {\genobf} handles finding {\keobf} instances using a given parameter $\sigma$. And, it either returns the found {\keobf} instance or failure signals.
The search starts with an initial guess of an upper bound $\sigma_{u}$, which is iterative doubled until a {\keobf} instance is found. Then, the binary search is performed over the range $[0,\sigma_{u}]$. The binary search terminates until the search interval is sufficiently short. The algorithm outputs the best {\keobf} found (the last one that was successfully generated).

\subsection{The function {\genobf}}
In reality, finding {\keobf} instances using a given parameter $\sigma$ is not that easy.
The function {\genobf} utilizes the randomized search to handle intractable search space. Multiple attempts are performed (In our experiment, 5 attempts are performed.). Iff all the attempts fail, {\genobf} returns failure signals, otherwise, returns the found {\keobf} instance. 

Each attempt begins by selecting a subset of edges, which will be subjected to alteration. Then, it assigns the deviation among selected edges and injects uncertainty. 
% The randomization process heavily relies on a single meta-heuristic. 
In particular, they suggest calibrating the perturbation applied to an edge $e$ according to the ``uniqueness" of the two nodes $u$ and $v$. 
% The calculation of uniqueness is covered in a sequent section. 
In brief, if both $u$ and $v$ are common nodes w.r.t the property, then $r_{e}$ should be very small; on the other hand, if $u$ and $v$ are outliers, then $r_{e}$ should be higher. Meanwhile, edges need to be sampled with the higher probability if they are adjacent to outliers. 


\subsection{Limitations} 
The above-mentioned approach achieves the desired level of obfuscation with the small change in the data, thus maintaining high utility 
However, the design heavily tailored towards the deterministic context. In the uncertain scenario, it suffers from following issues. 
First, its scheme does not consider the structural relevance of edges in critical edge selection/alteration steps, which leads to unnecessary structural distortion. 
Second, its scheme assumes the existence of edges is known with certainty, thus fails to handle uncertain graphs where the existence of edges is probabilistic. 
All the operators, such as selection and alteration, need to be integrated with possible world semantics carefully.  
We are left asking the question, \emph{how to generalize existing methods to the probabilistic context?}



